{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Prepare_corpus.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOyY/GKWQjuu9l8gBxKZxiT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zb4PISRD8avE"},"source":["# Jane Austen corpus\n","\n","Use text files of Jane Austen books from Project Gutenberg to create a Jane Austen Text Generator. Train a tokenizer and pickle it for later use, to encode and decode text."]},{"cell_type":"code","metadata":{"id":"sArpsB6BgrAR"},"source":["import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3k0fewcudK6"},"source":["import requests\n","url = 'https://www.gutenberg.org/files/1342/1342-0.txt'\n","path = requests.get(url)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjpNwlsiv10J"},"source":["with open('Pride_and_Prejudice.txt', 'wb') as f:\n","    f.write(path.content)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r1UMYwrkvUAl"},"source":["with open('Pride_and_Prejudice.txt', 'r') as f:\n","  lines = f.readlines()\n","  del lines[:164] # remove header lines that are not part of the book\n","  book = open(\"Pride_and_prejudice_processed.txt\", \"w+\")\n","  for line in lines:\n","    l = line.lstrip(' *').lower()\n","    r = re.match('^end of the project gutenberg',l) # remove the project gutenberg license at the end\n","    if not r:\n","      book.write(line.lstrip().replace('_','')) # strip whitespace from the left\n","      # _ is used to represent italicized text\n","    else:\n","      break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MyqClSWA9Pdm"},"source":["url = 'https://www.gutenberg.org/files/161/161-0.txt'\n","path = requests.get(url)\n","\n","with open('Sense_and_Sensibility.txt', 'wb') as f:\n","    f.write(path.content)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yojoWhVO-COG"},"source":["with open('Sense_and_Sensibility.txt', 'r') as f:\n","  lines = f.readlines()\n","  del lines[:93] # remove header lines that are not part of the book\n","  book = open(\"Sense_and_Sensibility_processed.txt\", \"w+\")\n","  for line in lines:\n","    l = line.lstrip(' *').lower()\n","    r = re.match('^end of the project gutenberg',l) # remove the project gutenberg license at the end\n","    if not r:\n","      book.write(line.lstrip().replace('_','')) # strip whitespace from the left\n","    else:\n","      break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sWu71asu_wI5"},"source":["url = 'https://www.gutenberg.org/files/158/158-0.txt'\n","path = requests.get(url)\n","\n","with open('Emma.txt', 'wb') as f:\n","    f.write(path.content)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o8liZwln_4SW"},"source":["with open('Emma.txt', 'r') as f:\n","  lines = f.readlines()\n","  del lines[:38] # remove header lines that are not part of the book\n","  book = open(\"Emma_processed.txt\", \"w+\")\n","  for line in lines:\n","    l = line.lstrip().lower()\n","    r = re.match('^end of the project gutenberg',l) # remove the project gutenberg license at the end\n","    if not r:\n","      book.write(line.lstrip().replace('_','')) # strip whitespace from the left\n","    else:\n","      break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZGVJdPybc46C"},"source":["url = 'https://www.gutenberg.org/cache/epub/105/pg105.txt'\n","path = requests.get(url)\n","\n","with open('Persuasion.txt', 'wb') as f:\n","    f.write(path.content)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"igLrXnindOm2"},"source":["with open('Persuasion.txt', 'r') as f:\n","  lines = f.readlines()\n","  del lines[:47] # remove header lines that are not part of the book\n","  book = open(\"Persuasion_processed.txt\", \"w+\")\n","  for line in lines:\n","    l = line.lstrip(' *').lower()\n","    r = re.match('^end of the project gutenberg',l) # remove the project gutenberg license at the end\n","    if not r:\n","      book.write(line.lstrip().replace('_','')) # strip whitespace from the left\n","    else:\n","      break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YszfntZHuVzm","executionInfo":{"status":"ok","timestamp":1616100550310,"user_tz":240,"elapsed":842,"user":{"displayName":"James Kreinbihl","photoUrl":"","userId":"17756256578181449259"}},"outputId":"3f76495d-f779-49b3-ef9f-0db36f0e9bd9"},"source":["books = {'Pride and Prejudice':'Pride_and_prejudice_processed.txt',\n","          'Emma':'Emma_processed.txt',\n","          'Persuasion':'Persuasion_processed.txt',\n","          'Sense and Sensibility':'Sense_and_Sensibility_processed.txt'}\n","corpus = ''\n","for title, text in books.items():\n","  with open(text, 'r') as f:\n","      corpus += title + '\\n' + f.read()\n","Austen_corpus = open('Austen_corpus.txt', 'w+')\n","Austen_corpus.write(corpus)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2692919"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"5IEe1sV9xPIK"},"source":["train_corp = open('Train_corp.txt', 'w+')\n","valid_corp = open('Valid_corp.txt', 'w+')\n","for title, text in books.items():\n","  with open(text, 'r') as f:\n","    lines = f.readlines()\n","    num_lines = len(lines)\n","    train = num_lines*90 // 100\n","    for line in lines[:train-1]:\n","      train_corp.write(line)\n","    for line in lines[-train:]:\n","      valid_corp.write(line)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IG6el4mg4OMn"},"source":["with open('Austen_corpus.txt', 'r') as f:\n","  corp = f.read()\n","with open('Train_corp.txt', 'r') as f:\n","  train_text = f.read()\n","with open('Valid_corp.txt', 'r') as f:\n","  valid_text = f.read()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ioHq0xHFw5nS"},"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2zIyZUn0xyYW"},"source":["tokenizer = Tokenizer(char_level = True)\n","tokenizer.fit_on_texts(corp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmbcF5tBGyxm"},"source":["import pickle \n","\n","# saving\n","with open('tokenizer.pickle', 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UtBbbEOd8bpD"},"source":[""],"execution_count":null,"outputs":[]}]}